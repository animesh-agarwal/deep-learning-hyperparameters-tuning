{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5Zw3AQ2TtTe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "4L8j6P0uT_A9",
    "outputId": "cb6617b1-6089-46e8-fce4-c1f84bf8fc65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TCvL6hZV5at"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,-1)\n",
    "x_test = x_test.reshape(10000,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcL1wREqYD4B"
   },
   "outputs": [],
   "source": [
    "# the values of x_train and x_test are between 0 and 255\n",
    "# compute the mean and standard deviation of the train set and \n",
    "# normalize the data\n",
    "def normalize(x_train, x_test):\n",
    "  train_mean = np.mean(x_train)\n",
    "  train_std = np.mean(x_train)\n",
    "  x_train = (x_train - train_mean)/train_std\n",
    "  x_test = (x_test - train_mean)/train_std  \n",
    "  return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRaKr6cCWNM5"
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(labels):\n",
    "  no_samples = labels.shape[0]\n",
    "  n_classes = np.max(labels) + 1\n",
    "  one_hot = np.zeros((no_samples, n_classes))\n",
    "  one_hot[np.arange(no_samples),labels.ravel()] = 1\n",
    "  return one_hot\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cALglfQdaHT5"
   },
   "outputs": [],
   "source": [
    "x_train, x_test = normalize(x_train, x_test)\n",
    "y_train = convert_to_one_hot(y_train)\n",
    "y_test = convert_to_one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxx12pnP2ufi"
   },
   "outputs": [],
   "source": [
    "def get_placeholders(input_size, output_size):\n",
    "  inputs = tf.placeholder(dtype=tf.float32, shape=[None, input_size], name=\"inputs\")\n",
    "  targets = tf.placeholder(dtype=tf.float32, shape=[None, output_size], name=\"targets\")\n",
    "  return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8dizgVeov7U"
   },
   "outputs": [],
   "source": [
    "def dense_layer(input, hidden_units, layer_no, kernel_initializer, activation_fn= tf.nn.relu):\n",
    "  weights_name = \"layer{}/kernel\".format(layer_no)\n",
    "  bias_name = \"layer{}/biases\".format(layer_no)\n",
    "  matmul_name = \"layer{}/MatMul\".format(layer_no)\n",
    "  weights = tf.get_variable(weights_name, shape=[input.shape[1], hidden_units], initializer = kernel_initializer)\n",
    "  biases = tf.get_variable(bias_name, shape=[hidden_units], initializer = tf.zeros_initializer())\n",
    "  matmul = tf.add(tf.matmul(input, weights), biases, name=matmul_name)\n",
    "  tf.summary.histogram('MatMul{}'.format(layer_no), matmul)\n",
    "  if activation_fn:\n",
    "    output =  activation_fn(matmul)\n",
    "  else:\n",
    "    output = matmul\n",
    "  tf.summary.histogram('Output{}'.format(layer_no), output)\n",
    "  return output\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GY4gCEDSoLhF"
   },
   "outputs": [],
   "source": [
    "def build_network(features, labels, hidden_units, num_layers, kernel_initializer, activation_fn):\n",
    "  inputs = features\n",
    "  for layer in range(num_layers-1):\n",
    "    inputs = dense_layer(inputs, hidden_units[layer], layer+1, kernel_initializer, activation_fn)\n",
    "  logits = dense_layer(inputs, 10, num_layers, kernel_initializer, None) \n",
    "  return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zoOh0rtwoi6"
   },
   "outputs": [],
   "source": [
    "def compute_loss(logits, labels):\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = labels , logits= logits))\n",
    "  optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "  tf.summary.scalar('loss', loss)\n",
    "  return loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8255Vt_rxDWo"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(logits, labels):\n",
    "  correct_predictions = tf.equal(tf.argmax(logits,1), tf.argmax(labels,1))\n",
    "  accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "  tf.summary.scalar('accuracy', accuracy)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R38sSFKWK1Ja"
   },
   "outputs": [],
   "source": [
    "def get_variance(x):\n",
    "  mean = tf.reduce_mean(x)\n",
    "  x_centered = tf.square(x-mean)\n",
    "  variance = tf.reduce_mean(x_centered)\n",
    "  return sess.run(variance)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5oseP_vMut3"
   },
   "outputs": [],
   "source": [
    "def get_matmul_tensors(num_layers):\n",
    "  def_graph = tf.get_default_graph()\n",
    "  return [def_graph.get_tensor_by_name('layer{}/MatMul:0'.format(layer+1)) for layer in  range(num_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_YpAHY02hGq"
   },
   "outputs": [],
   "source": [
    "def train_model(features, labels, hidden_units, epochs, batch_size, learning_rate, num_layers, kernel_initializer, activation_fn, file_name, single_pass=False):\n",
    "  tf.reset_default_graph()\n",
    "  input_size = features.shape[1]\n",
    "  output_size = labels.shape[1]\n",
    "  \n",
    "  # get the placeholders \n",
    "  inputs, targets = get_placeholders(input_size,output_size)\n",
    "  \n",
    "  # create a dataset\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "  \n",
    "  # make the required batches \n",
    "  dataset = dataset.batch(batch_size)\n",
    "  \n",
    "  # initialize the iterator for the dataset \n",
    "  iterator = dataset.make_initializable_iterator()\n",
    "  \n",
    "  # get the next batch\n",
    "  x_batch, y_batch = iterator.get_next()\n",
    "  \n",
    "  # forward network\n",
    "  logits = build_network(x_batch, y_batch, hidden_units, num_layers, kernel_initializer, activation_fn)\n",
    " \n",
    "  # compute the loss\n",
    "  loss, optimizer = compute_loss(logits, y_batch)\n",
    "\n",
    "  accuracy = compute_accuracy(logits, y_batch)\n",
    "  \n",
    "  init_op = tf.global_variables_initializer()\n",
    "  \n",
    "  merged_summary = tf.summary.merge_all()\n",
    "  \n",
    "  saver = tf.train.Saver()\n",
    "  \n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    def_graph = tf.get_default_graph()\n",
    "    train_samples = features.shape[0]\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter(file_name, sess.graph)\n",
    "    iteration = 0\n",
    "    \n",
    "    if single_pass:\n",
    "      sess.run(iterator.initializer, feed_dict={inputs:features, targets:labels})\n",
    "      try:\n",
    "        while iteration < 1:\n",
    "          summary = sess.run(merged_summary)\n",
    "          train_writer.add_summary(summary,iteration)\n",
    "          iteration += 1\n",
    "      except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "      \n",
    "    else:\n",
    "      for epoch in range(epochs):\n",
    "        # run the iterator's initializer\n",
    "        sess.run(iterator.initializer, feed_dict={inputs:features, targets:labels})\n",
    "        try:\n",
    "\n",
    "          while True:\n",
    "\n",
    "            batch_loss,  _ , batch_accuracy = sess.run([loss, optimizer, accuracy])\n",
    "            if iteration % 100 == 0:\n",
    "              summary = sess.run(merged_summary)\n",
    "              train_writer.add_summary(summary,iteration)\n",
    "            iteration += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "          pass\n",
    "        #print(\"Total Iterations {}\".format(iteration))\n",
    "        \n",
    "      \n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "ZIxBpRFS_sHV",
    "outputId": "a92c9877-2fd6-4b6e-a4e9-43649f075966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model - Sigmoid - Random Normal Initializer - Single Pass/debug\n",
      "Running model - Sigmoid - Xavier Initializer - Single Pass/debug\n",
      "Running model - RELU - Xavier Initializer - Full Pass/debug\n",
      "Running model - RELU - He Initializer - Full Pass/debug\n",
      "Running model - Sigmoid - Xavier Initializer - Full Pass/debug\n",
      "Running model - Sigmoid - Random Normal Initializer - Full Pass/debug\n",
      "Running model - RELU - Random Normal Initializer - Full Pass/debug\n"
     ]
    }
   ],
   "source": [
    "features = x_train\n",
    "labels = y_train\n",
    "epochs = 20\n",
    "batch_size = 256 \n",
    "learning_rate = 0.001\n",
    "\n",
    "num_layers = 4\n",
    "hidden_units = [100,100,100]\n",
    "input_units = x_train.shape[1]\n",
    "output_units = y_train.shape[1] \n",
    "\n",
    "random_normal_initializer = tf.random_normal_initializer\n",
    "xavier_initializer = tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_AVG', uniform=False)\n",
    "he_initializer = tf.contrib.layers.variance_scaling_initializer(factor=2.0, mode='FAN_IN', uniform=False)\n",
    "\n",
    "\n",
    "single_pass_models = {\n",
    "    \"Sigmoid - Random Normal Initializer - Single Pass\" : (tf.nn.sigmoid, random_normal_initializer),\n",
    "    \"Sigmoid - Xavier Initializer - Single Pass\" : (tf.nn.sigmoid, xavier_initializer)\n",
    "}\n",
    "\n",
    "full_pass_models = {\n",
    "    \"Sigmoid - Random Normal Initializer - Full Pass\" : (tf.nn.sigmoid, random_normal_initializer),\n",
    "    \"Sigmoid - Xavier Initializer - Full Pass\" : (tf.nn.sigmoid, xavier_initializer),\n",
    "    \"RELU - Random Normal Initializer - Full Pass\" : (tf.nn.relu, random_normal_initializer),\n",
    "    \"RELU - Xavier Initializer - Full Pass\" : (tf.nn.relu, xavier_initializer),\n",
    "    \"RELU - He Initializer - Full Pass\" : (tf.nn.relu, he_initializer),\n",
    "}\n",
    "\n",
    "all_models = [\n",
    "    (single_pass_models, True),\n",
    "    (full_pass_models, False)\n",
    "]\n",
    "\n",
    "tensorboard_dir = os.path.join(os.getcwd() , \"tensorboard_visualizations\")\n",
    "\n",
    "for models, single_pass in all_models:\n",
    "  for name, (activation_fn, kernel_initializer) in models.items():\n",
    "    model_name = \"Running model - {}/debug\".format(name)\n",
    "    file_name = os.path.join(tensorboard_dir, model_name)\n",
    "    print(model_name)\n",
    "    train_model(features = features,\n",
    "                  labels = labels, \n",
    "                  epochs = epochs, \n",
    "                  hidden_units = hidden_units,                                \n",
    "                  batch_size = batch_size, \n",
    "                  learning_rate = learning_rate, \n",
    "                  num_layers = num_layers, \n",
    "                  kernel_initializer = kernel_initializer,                               \n",
    "                  activation_fn = activation_fn, \n",
    "                  file_name = file_name,\n",
    "                  single_pass=single_pass)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of Weight Initialization in TensorFlow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
